{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataStrategisthjk/NLP/blob/main/Using_LSTM_model_for_sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWH3bdnFNUAY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/ratings_train.txt\", header=0, delimiter=\"\\t\", quoting=3)\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### I will be using NAVER movie review data to work on sentimental analysis.\n",
        "#### To do so, I would need a simple preprocessing before working with a deep learning model."
      ],
      "metadata": {
        "id": "K8VBv0-pQ6fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy # required to translate korean language"
      ],
      "metadata": {
        "id": "8sHNexkYRW-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "text = \"안녕하세요.\" # hello in korean\n",
        "\n",
        "okt.morphs(text, stem=True)"
      ],
      "metadata": {
        "id": "rSJUgerwQ2Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt.morphs(text, stem=False)"
      ],
      "metadata": {
        "id": "BXjkKqfRR-gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. extracted a list of string types\n",
        "2. filtered with regular expression (i.e., special characters, emoticons).\n",
        "3. eliminated stopwords and created a list."
      ],
      "metadata": {
        "id": "ZXXhZaiESeOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word = ['은', '는','이', '가','이다'] #morphological words in korean language.\n",
        "\n",
        "def preprocessing(content, okt):\n",
        "    content_re = re.sub(\"[^가-힣 ]\", \"\",content)\n",
        "    content_word = okt.morphs(content_re, stem=True)\n",
        "\n",
        "    word_list = []\n",
        "\n",
        "    for word in content_word:\n",
        "        if word not in stop_word:\n",
        "            word_list.append(word)\n",
        "\n",
        "    return word_list\n"
      ],
      "metadata": {
        "id": "SbBc2tZZSb-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing(\"안녕하세요 HJK입니다. 감성분류를 하고 있습니다.\", okt) #this means, \"hello this is hjk(my initial). I am doing sentimental analysis\" in korean language.\n"
      ],
      "metadata": {
        "id": "N3M6I8htUuiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "\n",
        "train_review = [] # empty list for data preprocessing\n",
        "\n",
        "for review in train['document'][:500]: # only 5 million words since not possible for 15 million words.\n",
        "    train_review.append(preprocessing(review, okt)) # preprocessing function with reviews and stemming.\n",
        "                                                    # append the return values, stack them at the train reviews.\n",
        "                                                    # Then, train review becomes 2d array.\n"
      ],
      "metadata": {
        "id": "-2UXBFSvU5pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_review"
      ],
      "metadata": {
        "id": "BR7mUcwFWtXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() #tool that changes words into numbers.\n",
        "\n",
        "#Defining the overall orders by tokenizers.\n",
        "#Define numbers by words\n",
        "#Construct dict for word - numbers.\n",
        "tokenizer.fit_on_texts(train_review)\n",
        "\n",
        "# change words into numbers by tokenizers for each reviews.\n",
        "train_sequence = tokenizer.texts_to_sequences(train_review)\n",
        "train_sequence # confirmation"
      ],
      "metadata": {
        "id": "SwXhQDlKYXux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeplearning model's input size has a length\n",
        "# Each reviews have different lengths.\n",
        "\n",
        "# if input size > 17, then can not enter.\n",
        "# Fit the size -> fill in with padding.\n",
        "\n",
        "train_input = pad_sequences(train_sequence, maxlen=8, padding=\"post\")\n",
        "\n",
        "# maxlen=8: paddin, length size of 8.\n",
        "# padding=\"post\": fill in with 0 from the back.\n",
        "train_input"
      ],
      "metadata": {
        "id": "QZALlp1EbfMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target val.\n",
        "\n",
        "train_label = np.array(train['label'])\n",
        "train_label\n"
      ],
      "metadata": {
        "id": "4632V_-_dkxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Constructing a model.\n",
        "\n",
        "# Function to split the data in an 8(training):2(evaluation) ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Training data, evaluation data, training answers, evaluation answers\n",
        "# Feature data, answer data, val data size ratio\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_input, train_label[:500], test_size=0.2)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense, Embedding\n",
        "\n",
        "model = Sequential() # Define model object\n",
        "word_size = len(tokenizer.word_index)+1\n",
        "model.add(Embedding(word_size, 128, input_length = 8)) # Word size, 128 output, 8 size input\n",
        "model.add(Flatten()) # If the embedding result is 2D, flatten it to make it a 1D vector\n",
        "model.add(Dense(1,activation='relu')) # Pass through the activation function relu to get an output of 1\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics =['accuracy'])\n",
        "             # Model configuration section, set optimizer to adam, compute loss with binary_crossentropy,\n",
        "             # Measure model performance with accuracy.\n",
        "\n",
        "model.fit(x_train,y_train, epochs=5, batch_size = 32)"
      ],
      "metadata": {
        "id": "ZFBqueWSeHn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_val,y_val)\n"
      ],
      "metadata": {
        "id": "gLzPgyz4kSVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"이 영화 너무 다시볼거야 너무 재밌다\" # \"this movie is very fun, and i will watch this one again\" in korean language.\n",
        "\n",
        "re_text = preprocessing(text, okt) # Preprocessing: regular expression, stemming, stopword processing\n",
        "text_data = []\n",
        "text_data.append(re_text) # It must be made in the form of n x n, as there is only one data,\n",
        "                          # It should go in like [[word list]].\n",
        "                          # If there are 2 pieces of data, It should go in 2 x n like [[word list],[word list]].\n",
        "text_seq = tokenizer.texts_to_sequences(text_data) # Convert word list to number list. It should be padded to a size of 8\n",
        "text_seq = pad_sequences(text_seq, maxlen = 8, padding = \"post\")\n",
        "model.predict(text_seq) # Evaluate positivity and negativity by inserting it into the model, negative towards 0, positive towards 1\n",
        "                        # As only 500 sentences are currently entered, the accuracy is low.\n"
      ],
      "metadata": {
        "id": "VBncXK8ikcQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LSTM model"
      ],
      "metadata": {
        "id": "DhIGoqDfmBHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 128, input_length = 8)) #Embedding layer configuration\n",
        "model.add(LSTM(units=128)) #Define LSTM model, units are the number of output features\n",
        "model.add(Dense(1,activation=\"relu\")) #Dense takes the output features of LSTM, passes through relu and outputs one.\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics =['accuracy'])\n",
        "early = EarlyStopping(monitor = \"val_loss\" , mode = \"min\", verbose = 1, patience = 5)\n",
        "model.fit(x_train,y_train, epochs=100, batch_size = 32, callbacks = [early],\n",
        "          validation_split = 0.2) #Total learning epochs 5, batch size is 32"
      ],
      "metadata": {
        "id": "9HaTNmlJmAq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_val,y_val)"
      ],
      "metadata": {
        "id": "EWUPwsAtoDY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"이 영화 너무 다시볼거야 너무 재밌다\"\n",
        "\n",
        "re_text = preprocessing(text, okt) #Preprocessing: regular expression, stemming, stopword processing\n",
        "text_data = []\n",
        "text_data.append(re_text) #It must be made in the form of n x n, since there is only one data\n",
        "                          #It should be entered like [[word list]]. If there are two data, it should go in as 2 x n like [[word list],[word list]].\n",
        "text_seq = tokenizer.texts_to_sequences(text_data) #Convert the word list into a list of numbers\n",
        "text_seq = pad_sequences(text_seq, maxlen = 8, padding = \"post\") #It should be padded to a size of 8.\n",
        "model.predict(text_seq) #Put it in the model and evaluate positive/negative, the closer to 0, the more negative, the closer to 1, the more positive.\n",
        "                        #As only 500 sentences are currently entered, the accuracy is low.\n"
      ],
      "metadata": {
        "id": "2yWlOYr_nPUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djWVrbff2ln-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}